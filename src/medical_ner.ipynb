{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934860dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_txt_to_json(txt_path, json_path, names):\n",
    "    import json\n",
    "    data = []\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        for idx, text in enumerate(f.read().split('\\n\\n')):\n",
    "            ner_tags = []\n",
    "            sample = {}\n",
    "            tokens = []\n",
    "            for line in text.split('\\n'):\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                token_tag = line.split()\n",
    "                if len(token_tag) != 2:\n",
    "                    continue\n",
    "                token, tag = token_tag\n",
    "                tokens.append(token)\n",
    "                if tag not in names:\n",
    "                    names.append(tag)\n",
    "                ner_tags.append(names.index(tag))\n",
    "            sample['id'] = idx\n",
    "            sample['tokens'] = tokens\n",
    "            sample['ner_tags'] = ner_tags\n",
    "            data.append(sample)\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd5877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-临床表现', 'I-临床表现', 'B-中医治疗', 'I-中医治疗', 'B-西医诊断', 'I-西医诊断', 'B-方剂', 'I-方剂', 'B-中药', 'I-中药', 'B-中医诊断', 'I-中医诊断', 'B-西医治疗', 'I-西医治疗', 'B-中医证候', 'I-中医证候', 'B-中医治则', 'I-中医治则', 'B-其他治疗', 'I-其他治疗']\n",
      "['O', 'B-临床表现', 'I-临床表现', 'B-中医治疗', 'I-中医治疗', 'B-西医诊断', 'I-西医诊断', 'B-方剂', 'I-方剂', 'B-中药', 'I-中药', 'B-中医诊断', 'I-中医诊断', 'B-西医治疗', 'I-西医治疗', 'B-中医证候', 'I-中医证候', 'B-中医治则', 'I-中医治则', 'B-其他治疗', 'I-其他治疗']\n",
      "['O', 'B-临床表现', 'I-临床表现', 'B-中医治疗', 'I-中医治疗', 'B-西医诊断', 'I-西医诊断', 'B-方剂', 'I-方剂', 'B-中药', 'I-中药', 'B-中医诊断', 'I-中医诊断', 'B-西医治疗', 'I-西医治疗', 'B-中医证候', 'I-中医证候', 'B-中医治则', 'I-中医治则', 'B-其他治疗', 'I-其他治疗']\n"
     ]
    }
   ],
   "source": [
    "# 用法示例\n",
    "names = []\n",
    "names = convert_txt_to_json('../data/medical/train.txt', '../data/medical/trian.json', names)\n",
    "print(names)\n",
    "names = convert_txt_to_json('../data/medical/dev.txt', '../data/medical/dev.json', names)\n",
    "print(names)\n",
    "names = convert_txt_to_json('../data/medical/test.txt', '../data/medical/test.json', names)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f69960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 5259 examples [00:00, 68725.45 examples/s]\n",
      "Generating dev split: 657 examples [00:00, 92341.59 examples/s]\n",
      "Generating test split: 658 examples [00:00, 108758.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Value, Features, ClassLabel, Sequence\n",
    "\n",
    "data_files = {'train': '../data/medical/train.json', 'dev': '../data/medical/dev.json', 'test': '../data/medical/test.json'}\n",
    "features = Features({\n",
    "    'id': Value('int32'),\n",
    "    'tokens': Sequence(Value('string')),\n",
    "    'ner_tags': Sequence(ClassLabel(num_classes=21, names=names))\n",
    "})\n",
    "\n",
    "raw_dataset = load_dataset('json', data_files=data_files, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa86b69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='int32', id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-临床表现', 'I-临床表现', 'B-中医治疗', 'I-中医治疗', 'B-西医诊断', 'I-西医诊断', 'B-方剂', 'I-方剂', 'B-中药', 'I-中药', 'B-中医诊断', 'I-中医诊断', 'B-西医治疗', 'I-西医治疗', 'B-中医证候', 'I-中医证候', 'B-中医治则', 'I-中医治则', 'B-其他治疗', 'I-其他治疗'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['dev'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807eaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['dev']['ner_tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3765a257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouke/Documents/project/stage3/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":\"2025-07-04T06:57:14.733515Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Os { code: 60, kind: TimedOut, message: \\\"Operation timed out\\\" } }) }). Retrying...\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":242}\n",
      "{\"timestamp\":\"2025-07-04T06:57:14.734728Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 1.070629693s before the next attempt\"},\"filename\":\"/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [29:33<00:00, 443.32s/it]   \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:24<00:00,  6.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "checkpoint = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02015110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [79072, 75606, 68065, 59355, 99677, 100721, 20929, 99375, 5122, 39165, 100040, 5373, 100721, 73743, 99200, 20109, 43497, 144227, 3837, 21287, 100489, 99662, 5373, 21287, 70927, 99471, 99200, 59496, 144227, 3837, 101545, 100693, 20109, 24918, 144227, 3837, 99243, 119594, 5373, 99789, 119670, 5373, 26288, 99789, 99200, 20109, 26022, 144227, 3837, 110168, 34317, 82847, 33517, 26022, 144227, 3837, 100818, 99808, 43497, 144227], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenizer(raw_dataset['dev'][0]['tokens'],truncation=True, is_split_into_words=True, max_length=512)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "698a45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    tokenized_examples = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True, max_length=512)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_examples.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "        labels.append(label_ids)\n",
    "    tokenized_examples['labels'] = labels\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6867f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5259/5259 [00:00<00:00, 15166.86 examples/s]\n",
      "Map: 100%|██████████| 657/657 [00:00<00:00, 15488.01 examples/s]\n",
      "Map: 100%|██████████| 658/658 [00:00<00:00, 14581.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5259\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 657\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 658\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = raw_dataset.map(process_func, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "823329d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 6.34kB [00:00, 3.56MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"seqeval\", module_type: \"metric\", features: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')}, usage: \"\"\"\n",
       "Produces labelling scores along with its sufficient statistics\n",
       "from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions: List of List of predicted labels (Estimated targets as returned by a tagger)\n",
       "    references: List of List of reference labels (Ground truth (correct) target values)\n",
       "    suffix: True if the IOB prefix is after type, False otherwise. default: False\n",
       "    scheme: Specify target tagging scheme. Should be one of [\"IOB1\", \"IOB2\", \"IOE1\", \"IOE2\", \"IOBES\", \"BILOU\"].\n",
       "        default: None\n",
       "    mode: Whether to count correct entity labels with incorrect I/B tags as true positives or not.\n",
       "        If you want to only count exact matches, pass mode=\"strict\". default: None.\n",
       "    sample_weight: Array-like of shape (n_samples,), weights for individual samples. default: None\n",
       "    zero_division: Which value to substitute as a metric value when encountering zero division. Should be on of 0, 1,\n",
       "        \"warn\". \"warn\" acts as 0, but the warning is raised.\n",
       "\n",
       "Returns:\n",
       "    'scores': dict. Summary of the scores for overall and per type\n",
       "        Overall:\n",
       "            'accuracy': accuracy,\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure,\n",
       "        Per type:\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> seqeval = evaluate.load(\"seqeval\")\n",
       "    >>> results = seqeval.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['MISC', 'PER', 'overall_precision', 'overall_recall', 'overall_f1', 'overall_accuracy']\n",
       "    >>> print(results[\"overall_f1\"])\n",
       "    0.5\n",
       "    >>> print(results[\"PER\"][\"f1\"])\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval_matric = evaluate.load('seqeval')\n",
    "seqeval_matric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f69849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label_list = names\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    result = seqeval_matric.compute(predictions=true_predictions, references=true_labels, mode='strict', scheme='IOB2')\n",
    "    return {\n",
    "        'precision': result['overall_precision'],\n",
    "        'recall': result['overall_recall'],\n",
    "        'f1': result['overall_f1'],\n",
    "        'accuracy': result['overall_accuracy']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0dfae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.91s/it]\n",
      "Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B-Instruct and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(checkpoint, num_labels=len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6965577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    per_device_eval_batch_size=2,\n",
    "    per_gpu_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    output_dir='./output',\n",
    "    logging_steps=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6fd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6t/0qb_x5nn6tz2dhvnrkgg2wzr0000gp/T/ipykernel_37286/2188959836.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, DataCollatorForTokenClassification\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['dev'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
